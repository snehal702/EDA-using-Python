# EDA-using-Python
It showcases the various projects on Exploratory Data Analysis done using Pandas, Statistics and Data Visualization

Project 1: TELCO CUSTOMER CHURN  
Description : To reduce the risk of losing customers by profiling and anticipating churness and taking proactive measures to earn profits & minimize the loss of
acquiring new customers  
Dataset: Kaggle dataset of a Telco Company of Customers Characteristics who churned in the last month  
Steps:   
  - EDA was performed using Pandas, Seaborn to analyze the characteristics of customers who to tend to churn by taking comparisons between to customer profiles
    one who churned and the other was who stayed with the company.  
  - Profile was divided into 3 categories:   
      - Demographics : fields like gender, partnered, dependent, age  
      - Phone Services signed up by customers : phone service, internet service, multiple lines service, online backup, security and so on  
      - Contract terms: fields like contract, payment method, paperless billing, charges, etc.  
  - Understanding the differnt types of churn and factors leading to them and decision life cycle of a subsriber which changes as per needs/ experience and figuring       out customers to priortize to retain   
  - Analyzing all these characteristics with each other and finding correlation between them and churn to understand the behaviour of customers who churn in order to 
  take proactive measures to retain them.  
  
  
  Project 2: ADVANCED HOUSE PRICE PREDICTION   
  Description: to perform data cleaning and exploration to get more cleaner data, derived metrics and insights/ hidden patterns from the dataset.  
  Dataset: Contains features of house that determine its sale price, 1460 records & 81 cols, kaggle dataset  
  Steps:  
    - EDA was performed stating the Missing values and their contribution in the data; Extracting derived metrics from existing features; Univariate and Bivariate 
    analysis of Numerical and Categorical Features; Presence of Outlier values was checked; Cardinality of Categorical features and the encoding techniques required       were determined.  
    - Feature Engineering was performed - to handle NA values, temporal Variables, Distribution checks for numerical columns, encoding of categorical variables  
    - Feature Scaling was performed - to scale down features to the same scale(Standarization was used)  
    - Correlations to determine highly correlated features wrt target variable Sale Price and to find out some not so important intercorrelated independent features.  
    - Thus a cleaner data was prepared for further anlaysis  
    
  
  Project 3: ZOMATO DATASET  
  Description: Based on various information or features about provided about the restuarant find out all such factors that affect the establishment of different 
  restuarants in that area. This Project mainly focused on EDA i.e. getting insights from the data.  
  Dataset: Kaggle dataset containing various features for a restuarant in a country/city  
  Steps:  
    - various insights were found out like countries having most business for zomato  
    - coutry wise rating distribution  
    - most used currency by different countries  
    - countries who didnt rate at all  
    - which countries had online delivery services  
    - which countries had table booking services  
    - distribution of zomato business in top 5 cities  
    - top 5 cusines and cusine wise ratings  
    - Most famous restuarant chains  
    
    
   Project 4: Flight Fare Predicition  
   Description: To find insights about the features or characteristics of a flight that determined its fare /prices  
   Dataset : Travel Details  of a customer i.e. his/her flight details that determines the fare  
   Steps:  
    - this project mainly focused on Feature Enginerring  
    - Exploring the data and getting information about the missing values in data and their distribution  
    - Handling those missing values  
    - Extracting Derived metrics from exisiting temporal variables in dataset and utilizing those for further analysis  
    - Eg: getting day and month from date_of_journey feature  
    - Encoding of Categorical features  
    - Correlations between features and target variable  
    - Some visualizations like bivariate analysis of each categorical variable wrt target column; univariate analysis of each individual feature; 
    flight fares wrt airlines etc.  
    
    
  Project 5: Demands for bikes  
  Description: To study the features that influence the demand for bikes on hourly basis in a complete city  
  Dataset: UCI dataset with 17380 records  
  Steps:  
    - Understaning the raw data first by studying each column and its values ranges and figuring out how the values should be and if any features will be correlated to
    each other; if any features we can drop; on extract some derived features from existing ones.  
    - Feature Selection was performed to eliminate useless features from the data  
    - Univariate and Bivariate analysis of data was performed for both continuous and categorical features : it gave insights of distribution of the data, relation
    of features wrt target variable demand; target variable distribution; any time series analysis needed like data was hourly demands for bikes
    so a derived feature considering the demand values wrt lag values for demand could be obtained  
    - Correlation of variables wrt target to see how good they predict the demand  
    - encoding of categorical features was done thus making the data ready for further anlaysis  
    
  
  
 
  
 
